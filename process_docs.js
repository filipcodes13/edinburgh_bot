require('dotenv').config();
const { createClient } = require('@supabase/supabase-js');
const { Pinecone } = require('@pinecone-database/pinecone');
const { GoogleGenerativeAI } = require('@google/generative-ai'); 
const fs = require('fs');
const path = require('path');

// --- KONFIGURACJA ---
const SUPABASE_URL = process.env.SUPABASE_URL; 
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_KEY;
const PINECONE_API_KEY = process.env.PINECONE_API_KEY;
const GOOGLE_API_KEY = process.env.GOOGLE_API_KEY;
const PINECONE_INDEX_NAME = 'airport-navigator-embeddings';

// Sprawdzenie, czy wszystkie klucze API sƒÖ dostƒôpne
if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY || !PINECONE_API_KEY || !GOOGLE_API_KEY) {
    console.error("B≈ÅƒÑD KRYTYCZNY: Brakuje kluczowych zmiennych ≈õrodowiskowych w pliku .env! Upewnij siƒô, ≈ºe wszystkie klucze sƒÖ ustawione.");
    process.exit(1);
}

// Inicjalizacja klient√≥w API
const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY);
const pinecone = new Pinecone({ apiKey: PINECONE_API_KEY });
const genAI = new GoogleGenerativeAI(GOOGLE_API_KEY); 

const docsPath = path.join(__dirname, 'airport_docs');
const EMBEDDING_MODEL = "embedding-001"; // Model do generowania wektor√≥w
const COMPLETION_MODEL = "gemini-1.5-pro-latest"; // Model do generowania odpowiedzi

/**
 * Bardziej inteligentna funkcja do dzielenia tekstu na fragmenty.
 * Stara siƒô nie przecinaƒá zda≈Ñ i zachowuje pewne nak≈Çadanie siƒô dla lepszego kontekstu.
 * @param {string} text - Pe≈Çny tekst dokumentu.
 * @param {number} chunkSize - Docelowy rozmiar fragmentu.
 * @param {number} chunkOverlap - Ile znak√≥w ma siƒô nak≈Çadaƒá.
 * @returns {string[]} Tablica fragment√≥w tekstu.
 */
function splitTextIntoChunks(text, chunkSize = 1000, chunkOverlap = 150) {
    const sentences = text.split(/(?<=[.?!])\s+/);
    const chunks = [];
    let currentChunk = "";

    for (const sentence of sentences) {
        if (currentChunk.length + sentence.length > chunkSize) {
            chunks.push(currentChunk);
            currentChunk = currentChunk.slice(-chunkOverlap); // Zachowaj kontekst
        }
        currentChunk += (currentChunk.length > 0 ? " " : "") + sentence;
    }
    if (currentChunk) {
        chunks.push(currentChunk);
    }
    return chunks;
}

/**
 * Generuje wektor (embedding) dla danego tekstu.
 * @param {string} text Tekst do przetworzenia.
 * @returns {Promise<number[]>} Wektor osadzenia.
 */
async function generateEmbedding(text) {
    try {
        const model = genAI.getGenerativeModel({ model: EMBEDDING_MODEL });
        const result = await model.embedContent(text);
        return result.embedding.values;
    } catch (error) {
        console.error("B≈ÇƒÖd podczas generowania wektora przez Gemini:", error.message);
        if (error.message.includes('429')) { // Prosta obs≈Çuga b≈Çƒôd√≥w rate limiting
             console.log("Przekroczono limit zapyta≈Ñ. Czekam 5 sekund...");
             await new Promise(resolve => setTimeout(resolve, 5000));
             return generateEmbedding(text); 
        }
        throw error;
    }
}

/**
 * G≈Ç√≥wna funkcja orkiestrujƒÖca proces.
 */
async function uploadFilesAndEmbeddings() {
    console.log('üöÄ Rozpoczynam wysy≈Çanie plik√≥w i osadze≈Ñ do baz danych...');

    try {
        // Sprawdzenie, czy indeks Pinecone istnieje
        const pineconeIndexList = await pinecone.listIndexes();
        if (!pineconeIndexList.indexes || !pineconeIndexList.indexes.some(idx => idx.name === PINECONE_INDEX_NAME)) {
            console.error(`‚ùå B≈ÅƒÑD: Indeks Pinecone '${PINECONE_INDEX_NAME}' nie istnieje! Utw√≥rz go najpierw w panelu Pinecone.`);
            return;
        }

        const index = pinecone.index(PINECONE_INDEX_NAME);
        const filesToProcess = fs.readdirSync(docsPath).filter(file => file.endsWith('.txt'));

        if (filesToProcess.length === 0) {
            console.warn("‚ö†Ô∏è Brak plik√≥w .txt w folderze 'airport_docs' do przetworzenia.");
            return;
        }

        for (const fileName of filesToProcess) {
            console.log(`\n--- üìÑ Przetwarzam plik: ${fileName} ---`);
            const filePath = path.join(docsPath, fileName);
            const content = fs.readFileSync(filePath, 'utf-8');

            // 1. Zapis/aktualizacja pe≈Çnej tre≈õci pliku w Supabase
            const { error: upsertError } = await supabase
                .from('documents')
                .upsert({ filename: fileName, content: content }, { onConflict: 'filename' });

            if (upsertError) {
                 console.error(`  ‚ùå B≈ÇƒÖd przy zapisie pliku ${fileName} w Supabase:`, upsertError.message);
            } else {
                 console.log(`  ‚úÖ Plik ${fileName} pomy≈õlnie zapisany w Supabase.`);
            }

            // 2. Dzielenie tekstu, tworzenie wektor√≥w i wysy≈Çanie do Pinecone
            const textChunks = splitTextIntoChunks(content);
            console.log(`  Plik pociƒôty na ${textChunks.length} sp√≥jnych fragment√≥w. Generujƒô wektory...`);
            
            const vectorsToUpsert = [];
            for (let i = 0; i < textChunks.length; i++) {
                // Op√≥≈∫nienie, aby nie przekroczyƒá limit√≥w API Gemini (ok. 60 zapyta≈Ñ na minutƒô)
                await new Promise(resolve => setTimeout(resolve, 1100));

                const chunk = textChunks[i];
                if (!chunk || chunk.trim().length === 0) continue;

                try {
                    const embedding = await generateEmbedding(chunk);
                    vectorsToUpsert.push({
                        id: `${fileName}_chunk_${i}`,
                        values: embedding,
                        metadata: { filename: fileName, chunk_index: i, text_chunk: chunk }
                    });
                    console.log(`  üß† Wygenerowano wektor dla fragmentu ${i + 1}/${textChunks.length}`);
                } catch (embeddingError) {
                    console.error(`  ‚ùå B≈ÇƒÖd podczas generowania wektora dla fragmentu ${i} pliku ${fileName}. Pomijam ten fragment.`);
                }
            }

            // 3. Wysy≈Çanie wektor√≥w do Pinecone w paczkach (batching)
            if (vectorsToUpsert.length > 0) {
                console.log(`  üì§ Wysy≈Çam ${vectorsToUpsert.length} wektor√≥w dla pliku ${fileName} do Pinecone...`);
                // Pinecone zaleca wysy≈Çanie w paczkach po max 100 wektor√≥w
                for (let i = 0; i < vectorsToUpsert.length; i += 100) {
                    const batch = vectorsToUpsert.slice(i, i + 100);
                    await index.upsert(batch);
                }
                console.log(`  üå≤ Osadzenia dla pliku ${fileName} pomy≈õlnie przes≈Çane do Pinecone.`);
            }
        }
        console.log('\n\nüéâ --- Proces zako≈Ñczony! --- üéâ');
        console.log('Wszystkie dane zosta≈Çy przetworzone i wys≈Çane do Twoich baz danych.');

    } catch (error) {
        console.error("\n\nüî• !!! WystƒÖpi≈Ç krytyczny b≈ÇƒÖd podczas ca≈Çego procesu !!! üî•");
        console.error("B≈ÇƒÖd:", error.message);
    }
}

// Uruchomienie g≈Ç√≥wnej funkcji
uploadFilesAndEmbeddings();